# %%
import torch.nn as nn
import torch
import math

# %% [markdown]
# ### 模型定义：

# %%
"""
DDPM 模型需要的输入包括 噪声图像xt 和 时间步t ，输出为预测的噪声ϵθ(xt,t)。

首先，我们定义一个时间嵌入层，它负责将时间信息注入到特征中，将 时间步t 映射为高维向量。
参考 Transformer 中的位置编码方法，使用正余弦函数将时间步映射到高维空间。公式为：
                        PE(t, 2i) = sin(t / 10000^(2i/d))
                        PE(t, 2i+1) = cos(t / 10000^(2i/d))
其中，d为嵌入维度，t为维度索引。                    
"""
class SinusoidalPositionEmbeddings(nn.Module):
    def __init__(self, dim):
        super().__init__()
        
        self.dim = dim
    
    def forward(self, time):
        device = time.device

        # 将维度分为两半，分别用于sin和cos
        half_dim = self.dim // 2

        # 计算不同频率的指数衰减
        embeddings = math.log(10000) / (half_dim - 1)

        # 生成频率序列
        embeddings = torch.exp(
            torch.arange(half_dim, device=device) * -embeddings
        )

        # 将时间步与频率序列相乘
        embeddings = time[:, None] * embeddings[None, :]

        # 拼接sin和cos得到最终的嵌入向量
        embeddings = torch.cat(
            (embeddings.sin(), embeddings.cos()),
            dim = -1
        )

        return embeddings

# %%
"""
接着，定义一个U-Net的基本模块Block，包含时间嵌入、上、下采样功能。

第一次卷积扩展通道数，然后加入时间嵌入，接着进行第二次卷积，融合特征信息，最后进行上、下采样。

注：这里使用简化版U-Net，未使用原文中带有注意力机制的模型。
"""
class Block(nn.Module):
    def __init__(self, in_channels, out_channels, time_emb_dim, up=False):
        super().__init__()
        
        self.time_mlp = nn.Linear(time_emb_dim, out_channels)

        if up:
            self.conv1 = nn.Conv2d(2 * in_channels, out_channels, kernel_size=3, padding=1)     # 由于 U-Net 的残差连接,上采样时会 concat 之前的特征，输入通道数需要翻倍
            self.transform = nn.ConvTranspose2d(out_channels, out_channels, kernel_size=4, stride=2, padding=1)
        else:
            self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)
            self.transform = nn.Conv2d(out_channels, out_channels, kernel_size=4, stride=2, padding=1)
        
        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)
        self.bnorm1 = nn.BatchNorm2d(out_channels)
        self.bnorm2 = nn.BatchNorm2d(out_channels)

        self.relu = nn.ReLU()

    def forward(self, x, t):
        # 第一次卷积
        h = self.bnorm1(self.relu(self.conv1(x)))

        # 时间嵌入
        time_emb = self.relu(self.time_mlp(t))

        # 将时间信息注入特征图
        h = h + time_emb[..., None, None]

        # 第二次卷积
        h = self.bnorm2(self.relu(self.conv2(h)))

        # 上采样或下采样
        return self.transform(h)

# %%
"""
最后，将多个Block组合起来，形成一个U-Net模型。
每一层都会加入时间步信息，最终输出与输入图像尺寸相同的预测噪声。
"""
class SimpleUnet(nn.Module):
    def __init__(self):
        super().__init__()

        image_channels = 3
        down_channels = (64, 128, 256, 512, 1024)
        up_channels = (1024, 512, 256, 128, 64)
        out_dim = 3
        time_emb_dim = 32

        # 时间嵌入层
        self.time_embed = nn.Sequential(
            SinusoidalPositionEmbeddings(time_emb_dim),
            nn.Linear(time_emb_dim, time_emb_dim)
        )

        # 输入层、下采样层、上采样层和输出层
        self.input = nn.Conv2d(image_channels, down_channels[0], kernel_size=3, padding=1)
        self.downs = nn.ModuleList([Block(down_channels[i], down_channels[i + 1], time_emb_dim) for i in range(len(down_channels) - 1)])
        self.ups = nn.ModuleList([Block(up_channels[i], up_channels[i + 1], time_emb_dim, up=True) for i in range(len(up_channels) - 1)])
        self.output = nn.Conv2d(up_channels[-1], out_dim, kernel_size=3, padding=1)

    def forward(self, x, time_step):
        # 时间步嵌入
        t = self.time_embed(time_step)

        # 初步卷积
        x = self.input(x)

        # UNet前向传播：先下采样收集特征，再上采样恢复分辨率
        residual_stack = []
        for down in self.downs:
            x = down(x, t)
            residual_stack.append(x)
        for up in self.ups:
            residual_x = residual_stack.pop()
            x = torch.cat((x, residual_x), dim=1)
            x = up(x, t)
        
        return self.output(x)

# %% [markdown]
# ### 训练：

# %%
"""
首先需要定义一个噪声调度器，用于控制加噪过程，生成不同时间步的噪声图像。

在前向过程中，需要定义变量。
这里使用 register_buffer 来定义变量，这样这些变量就会自动与模型参数一起保存和加载。
"""
class Noisescheduler(nn.Module):
    def __init__(self, beta_start=0.0001, beta_end=0.02, num_steps=1000):
        super().__init__()
        self.beta_start = beta_start
        self.beta_end = beta_end
        self.num_steps = num_steps

        # β_t: 线性噪声调度
        self.register_buffer('betas', torch.linspace(beta_start, beta_end, num_steps))
        
        # α_t = 1 - β_t 
        self.register_buffer('alphas', 1.0 - self.betas)
        
        # α_bar_t = ∏(1-β_i) from i=1 to t
        self.register_buffer('alpha_bar', torch.cumprod(self.alphas, dim=0))

        # sqrt(α_bar_t)
        self.register_buffer('sqrt_alpha_bar', torch.sqrt(self.alpha_bar))

        # sqrt(1-α_bar_t)
        self.register_buffer('sqrt_one_minus_alpha_bar', torch.sqrt(1.0 - self.alpha_bar))


